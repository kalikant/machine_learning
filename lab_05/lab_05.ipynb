{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required packages and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#importing the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "#Read in data into a dataframe\n",
    "data = pd.read_csv(r\"./Datasets/Energy_and_Water_Data.csv\")\n",
    "\n",
    "#Display top of dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "#Diplay upto 60 columns of a dataset\n",
    "pd.set_option('display.max_columns', 60)\n",
    "#Set default font size\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set(font_scale = 1)\n",
    "#Internal ipython tool for setting figure size\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see the column data types and non-missing values\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to correct types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all occurances of Not Available with numpy not a number\n",
    "data = data.replace({\"Not Available\":np.nan})\n",
    "\n",
    "for col in list(data.columns):\n",
    "    if ('ft²' in col or 'kBtu' in col or 'Metric Tons CO2e' in col or 'kWh' in \n",
    "        col or 'therms' in col or 'gal' in col or 'Score' in col):\n",
    "        # Convert the data types to float\n",
    "        data[col] = data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics for each column\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate missing values by column\n",
    "def missing_values_table(df):\n",
    "    #Total missing values\n",
    "    mis_val = df.isnull().sum()\n",
    "    \n",
    "    #percentage of missing values\n",
    "    mis_val_percent = 100 * df.isnull().sum()/len(df)\n",
    "    \n",
    "    mis_val_table = pd.concat([mis_val,mis_val_percent],axis=1)\n",
    "    \n",
    "    #Rename the columns\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(columns = {0:'Missing Values', 1 : '% of Total Values'})\n",
    "    \n",
    "    #Sort the table by percentage of missing descending\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] !=0\n",
    "    ].sort_values('% of Total Values', ascending = False).round(1)\n",
    "    \n",
    "    #print some summary information\n",
    "    print(\"Your selected dataframe has \" + str(df.shape[1]) +\n",
    "         \" columns.\\n\"\n",
    "         \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "         \" columns that have missing values.\")\n",
    "    # Return the dataframe with missing information\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = missing_values_table(data)\n",
    "missing_columns = list(missing_df[missing_df['% of Total Values'] > 50].index)\n",
    "print('we will remove %d columns.' % len(missing_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "data = data.drop(columns = list(missing_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_subset = data.select_dtypes('number')\n",
    "categorical_subset = data.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_subset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imputer object with a median filling strategy\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "num_imputer.fit(numeric_subset)\n",
    "\n",
    "num_data = num_imputer.transform(numeric_subset)\n",
    "print(\"Missing values in numeric variables: \", np.isnan(num_data).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imputer object with a mode filling strategy\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "cat_imputer.fit(categorical_subset)\n",
    "\n",
    "cat_data = cat_imputer.transform(categorical_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.DataFrame(num_data, columns =  numeric_subset.columns)\n",
    "\n",
    "cat_df = pd.DataFrame(cat_data, columns = categorical_subset.columns)\n",
    "\n",
    "mod_data = pd.concat([num_df, cat_df], axis=1)\n",
    "mod_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_df = pd.DataFrame( num_data, columns =  numeric_subset.columns)\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data = pd.concat([num_df, cat_df], axis=1)\n",
    "mod_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# Rename the socre\n",
    "data = data.rename(columns = {'ENERGY STAR Score' : 'Score'})\n",
    "\n",
    "# Histogram of the Energy Star Score\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.hist(data['Score'].dropna(), bins = 100, edgecolor = 'k')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Number of Buildings')\n",
    "plt.title('Energy Star Score Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot of site EUI\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(data['Site EUI (kBtu/ft²)'].dropna(),bins=20,edgecolor='black')\n",
    "plt.xlabel('Site EUI')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Site EUI Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Site EUI (kBtu/ft²)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Site EUI (kBtu/ft²)'].dropna().sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Site EUI (kBtu/ft²)'] == 869265.0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate first and third quartile\n",
    "first_quantile = data['Site EUI (kBtu/ft²)'].describe()['25%']\n",
    "third_quantile = data['Site EUI (kBtu/ft²)'].describe()['75%']\n",
    "\n",
    "# Interquartile range\n",
    "iqr = third_quantile - first_quantile\n",
    "\n",
    "#Remove outliers\n",
    "data = data[(data['Site EUI (kBtu/ft²)'] > (first_quantile - 3 * iqr)) & \n",
    "            (data['Site EUI (kBtu/ft²)'] < (third_quantile + 3 * iqr))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot of site EUI\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.hist(data['Site EUI (kBtu/ft²)'].dropna(),bins=20,edgecolor='black')\n",
    "plt.xlabel('Site EUI')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Site EUI Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Site EUI (kBtu/ft²)'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_df:\n",
    "    print('\\nFrequency of categories for variable %s'%col)\n",
    "    print(cat_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = data.dropna(subset=['Score'])\n",
    "types = types['Largest Property Use Type'].value_counts()\n",
    "types = list(types[types.values > 100].index)\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of distribution of scores for building categories\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "\n",
    "# plot each building\n",
    "for b_type in types:\n",
    "    #select the building type\n",
    "    subset = data[data['Largest Property Use Type'] == b_type]\n",
    "    # Density plot of Energy Star Scores\n",
    "    sns.kdeplot(subset['Score'].dropna(),\n",
    "               label = b_type, shade = False,\n",
    "               alpha = 0.8)\n",
    "\n",
    "# label the plot\n",
    "plt.xlabel('Energy Star Score', size = 25)\n",
    "plt.ylabel('Density', size = 25); \n",
    "plt.title('Density Plot of Energy Star Scores by Building Type', size = 25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of boroughs with more than 100 observations\n",
    "boroughs = data.dropna(subset=['Score'])\n",
    "boroughs = boroughs['Borough'].value_counts()\n",
    "boroughs = list(boroughs[boroughs.values > 100].index)\n",
    "boroughs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of distribution scores of boroughs\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# Plot each borough\n",
    "for b_borough in boroughs:\n",
    "    subset = data[data['Borough'] == b_borough]\n",
    "    sns.kdeplot(subset['Score'].dropna(),\n",
    "               label = b_borough, shade = False,\n",
    "               alpha = 0.8)\n",
    "\n",
    "plt.xlabel(\"Energy Star Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density plot of Energy Star Score by Borough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find all correlations and sort\n",
    "correlations_data = data.corr()['Score'].sort_values()\n",
    "\n",
    "# Print the most negative correlations\n",
    "print(correlations_data.head(15), '\\n')\n",
    "\n",
    "# Print the most positive correlations\n",
    "print(correlations_data.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_subset = data.select_dtypes('number')\n",
    "\n",
    "# Create columns with square root and log of numeric columns\n",
    "for col in numeric_subset.columns:\n",
    "    # Skip the Energy Star Score column\n",
    "    if col == 'Score':\n",
    "        next\n",
    "    else:\n",
    "        numeric_subset['sqrt_' + col] = np.sqrt(numeric_subset[col])\n",
    "        numeric_subset['log_' + col] = np.log(numeric_subset[col])\n",
    "\n",
    "# Select the categorical columns\n",
    "categorical_subset = data[['Borough', 'Largest Property Use Type']]\n",
    "\n",
    "# One hot encode\n",
    "categorical_subset = pd.get_dummies(categorical_subset)\n",
    "\n",
    "# Join the two dataframes using concat\n",
    "# Make sure to use axis = 1 to perform a column bind\n",
    "features = pd.concat([numeric_subset, categorical_subset], axis = 1)\n",
    "\n",
    "# Drop buildings without an energy star score\n",
    "features = features.dropna(subset = ['Score'])\n",
    "\n",
    "# Find correlations with the score \n",
    "correlations = features.corr()['Score'].dropna().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display most negative correlations\n",
    "correlations.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display most positive correlations\n",
    "correlations.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "# Extract the building types\n",
    "features['Largest Property Use Type'] = data.dropna(subset = ['Score'])['Largest Property Use Type']\n",
    "\n",
    "# Limit to building types with more than 100 observations\n",
    "features = features[features['Largest Property Use Type'].isin(types)]\n",
    "\n",
    "# Use seaborn to plot a scatterplot of Score Vs Log Source EUI\n",
    "sns.lmplot('Site EUI (kBtu/ft²)', 'Score', \n",
    "           hue = 'Largest Property Use Type',\n",
    "          data = features,\n",
    "          scatter_kws = {'alpha':0.8, 's':60},\n",
    "          fit_reg = False, size = 12, aspect = 1.2)\n",
    "\n",
    "# Plot labeling\n",
    "plt.xlabel(\"Site EUI\", size = 28)\n",
    "plt.ylabel(\"Energy Star Score\", size = 28)\n",
    "plt.title(\"Energy Star Score vs Site EUI\", size = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the columns to  plot\n",
    "plot_data = features[['Score', 'Site EUI (kBtu/ft²)', \n",
    "                      'Weather Normalized Source EUI (kBtu/ft²)', \n",
    "                      'log_Total GHG Emissions (Metric Tons CO2e)']]\n",
    "\n",
    "# Replace the inf with nan\n",
    "plot_data = plot_data.replace({np.inf: np.nan, -np.inf: np.nan})\n",
    "\n",
    "# Rename columns \n",
    "plot_data = plot_data.rename(columns = {'Site EUI (kBtu/ft²)': 'Site EUI', \n",
    "                                        'Weather Normalized Source EUI (kBtu/ft²)': 'Weather Norm EUI',\n",
    "                                        'log_Total GHG Emissions (Metric Tons CO2e)': 'log GHG Emissions'})\n",
    "\n",
    "# Drop na values\n",
    "plot_data = plot_data.dropna()\n",
    "\n",
    "# Function to calculate correlation coefficient between two columns\n",
    "def corr_func(x, y, **kwargs):\n",
    "    r = np.corrcoef(x, y)[0][1]\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}\".format(r),\n",
    "               xy=(.2, .8), xycoords = ax.transAxes,\n",
    "               size = 10)\n",
    "\n",
    "# Create the pairgrid object\n",
    "grid = sns.PairGrid(data = plot_data, size = 3)\n",
    "\n",
    "# Upper is a scatter plot\n",
    "grid.map_upper(plt.scatter, color = 'blue', alpha = 0.6)\n",
    "\n",
    "# Diagonal is a histogram\n",
    "grid.map_diag(plt.hist, color = 'blue', edgecolor = 'black')\n",
    "\n",
    "# Bottom is correlation and density plot\n",
    "grid.map_lower(corr_func)\n",
    "grid.map_lower(sns.kdeplot,cmap = plt.cm.Reds)\n",
    "\n",
    "#Title for entire plot\n",
    "plt.suptitle('Pairs Plot of Engery Data', size = 25, y = 1.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = plot_data.corr()\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(corr, vmax=1,annot_kws={'size': 15}, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will limit the graph to building types that have \n",
    "# more than 100 observations in the dataset.\n",
    "building_types = data.dropna(subset=['Score'])\n",
    "building_types = building_types['Largest Property Use Type'].value_counts()\n",
    "building_types = list(building_types[building_types.values > 100].index)\n",
    "print(\"Buidling types with more than 100 observations \",building_types)\n",
    "\n",
    "# Create a list of boroughs with more than 100 observations\n",
    "boroughs = data.dropna(subset=['Score'])\n",
    "boroughs = boroughs['Borough'].value_counts()\n",
    "boroughs = list(boroughs[boroughs.values > 100].index)\n",
    "print(\"Boroughs with more than 100 observations \",boroughs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multivari_data = data[data['Largest Property Use Type'].isin(building_types) & \n",
    "                      data['Borough'].isin(boroughs)].dropna()\n",
    "multivari_data.rename(columns = {'Largest Property Use Type':\"BuildingType\"}, \n",
    "                      inplace = True)\n",
    "multivari_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "x=sns.FacetGrid(multivari_data, row='Borough',col = 'BuildingType',\n",
    "                palette='husl',sharex=False,sharey=False, margin_titles=True)\n",
    "x=x.map(plt.hist, 'Score', bins=15)\n",
    "x=x.fig.subplots_adjust(wspace=0.5, hspace=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program assignment solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "MTcars = pd.read_csv(\"./Datasets/mtcars.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTcars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTcars['cyl'] = MTcars['cyl'].astype('object')\n",
    "MTcars['vs'] = MTcars['am'].astype('object')\n",
    "MTcars['am'] = MTcars['am'].astype('object')\n",
    "MTcars['gear'] = MTcars['gear'].astype('object')\n",
    "MTcars['carb'] = MTcars['carb'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTcars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of mpg variable\n",
    "plt.hist(MTcars['mpg'], bins = 7, edgecolor = 'k')\n",
    "plt.xlabel('Mpg')\n",
    "plt.ylabel('Number of kilometers')\n",
    "plt.title('Miles/US Gallon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTcars.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = MTcars.corr()\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "sns.heatmap(cor, vmax=1,annot_kws={'size': 15}, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MTcars.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "x=sns.FacetGrid(MTcars, col='cyl',\n",
    "                palette='husl',sharex=False,sharey=False, margin_titles=True)\n",
    "x=x.map(plt.hist, 'mpg', bins=15)\n",
    "x=x.fig.subplots_adjust(wspace=0.5, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "x=sns.FacetGrid(MTcars, col='am',\n",
    "                palette='husl',sharex=False,sharey=False, margin_titles=True)\n",
    "x=x.map(plt.hist, 'mpg', bins=15)\n",
    "x=x.fig.subplots_adjust(wspace=0.5, hspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "x=sns.FacetGrid(MTcars, col='gear',\n",
    "                palette='husl',sharex=False,sharey=False, margin_titles=True)\n",
    "x=x.map(plt.hist, 'mpg', bins=15)\n",
    "x=x.fig.subplots_adjust(wspace=0.5, hspace=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
